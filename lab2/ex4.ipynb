{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13a00c47",
   "metadata": {},
   "source": [
    "# Ensemble Anomaly Detection with KNN/LOF\n",
    "\n",
    "This notebook implements an ensemble approach using multiple KNN or LOF models with different n_neighbors parameters, combining their predictions using average and maximization strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53c49e48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T08:50:33.722596Z",
     "start_time": "2025-10-28T08:50:33.719384Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from pyod.models.knn import KNN\n",
    "from pyod.models.lof import LOF\n",
    "from pyod.utils.utility import standardizer\n",
    "from pyod.models.combination import average, maximization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcb0c192",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T08:50:33.735825Z",
     "start_time": "2025-10-28T08:50:33.725126Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (1831, 21)\n",
      "Number of samples: 1831\n",
      "Number of features: 21\n",
      "Number of anomalies: 176\n",
      "Number of normal samples: 1655\n",
      "Contamination rate: 0.0961\n"
     ]
    }
   ],
   "source": [
    "# Load the cardio.mat dataset\n",
    "data = scipy.io.loadmat('cardio.mat')\n",
    "\n",
    "# Extract features and labels\n",
    "X = data['X']\n",
    "y = data['y'].ravel()\n",
    "\n",
    "print(f\"Dataset shape: {X.shape}\")\n",
    "print(f\"Number of samples: {len(X)}\")\n",
    "print(f\"Number of features: {X.shape[1]}\")\n",
    "print(f\"Number of anomalies: {np.sum(y == 1)}\")\n",
    "print(f\"Number of normal samples: {np.sum(y == 0)}\")\n",
    "print(f\"Contamination rate: {np.sum(y == 1) / len(y):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c402f3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T08:50:33.774650Z",
     "start_time": "2025-10-28T08:50:33.767884Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 1281\n",
      "Test set size: 550\n",
      "Training anomalies: 123\n",
      "Test anomalies: 53\n"
     ]
    }
   ],
   "source": [
    "# Split the data into train and test sets (stratify on y to keep the ratio of anomalies)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=1, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")\n",
    "print(f\"Training anomalies: {np.sum(y_train == 1)}\")\n",
    "print(f\"Test anomalies: {np.sum(y_test == 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8287b4c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T08:50:33.796784Z",
     "start_time": "2025-10-28T08:50:33.791672Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data normalized successfully\n",
      "Training set mean: -0.000000\n",
      "Training set std: 1.000000\n"
     ]
    }
   ],
   "source": [
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "\n",
    "print(\"Data normalized successfully\")\n",
    "print(f\"Training set mean: {X_train_normalized.mean():.6f}\")\n",
    "print(f\"Training set std: {X_train_normalized.std():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "525556d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T08:50:33.821549Z",
     "start_time": "2025-10-28T08:50:33.817342Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contamination rate: 0.0960\n"
     ]
    }
   ],
   "source": [
    "# Calculate contamination rate for the dataset\n",
    "contamination = np.sum(y_train == 1) / len(y_train)\n",
    "print(f\"Contamination rate: {contamination:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8fbf2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T08:50:36.155897Z",
     "start_time": "2025-10-28T08:50:33.846931Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 10 KNN models\n",
      "n_neighbors values: [30, 40, 50, 60, 70, 80, 90, 100, 110, 120]\n",
      "\n",
      "--- Model 1/10: KNN with n_neighbors=30 ---\n",
      "Train BA: 0.6968\n",
      "Test BA: 0.6740\n",
      "\n",
      "--- Model 2/10: KNN with n_neighbors=40 ---\n",
      "Train BA: 0.7090\n",
      "Test BA: 0.6864\n",
      "\n",
      "--- Model 3/10: KNN with n_neighbors=50 ---\n",
      "Train BA: 0.7176\n",
      "Test BA: 0.7147\n",
      "\n",
      "--- Model 4/10: KNN with n_neighbors=60 ---\n",
      "Train BA: 0.7176\n",
      "Test BA: 0.7242\n",
      "\n",
      "--- Model 5/10: KNN with n_neighbors=70 ---\n",
      "Train BA: 0.7266\n",
      "Test BA: 0.7430\n",
      "\n",
      "--- Model 6/10: KNN with n_neighbors=80 ---\n",
      "Train BA: 0.7441\n",
      "Test BA: 0.7525\n",
      "\n",
      "--- Model 7/10: KNN with n_neighbors=90 ---\n",
      "Train BA: 0.7486\n",
      "Test BA: 0.7525\n",
      "\n",
      "--- Model 8/10: KNN with n_neighbors=100 ---\n",
      "Train BA: 0.7527\n",
      "Test BA: 0.7525\n",
      "\n",
      "--- Model 9/10: KNN with n_neighbors=110 ---\n",
      "Train BA: 0.7486\n",
      "Test BA: 0.7535\n",
      "\n",
      "--- Model 10/10: KNN with n_neighbors=120 ---\n",
      "Train BA: 0.7527\n",
      "Test BA: 0.7639\n",
      "All models trained successfully\n"
     ]
    }
   ],
   "source": [
    "# Define n_neighbors range (30 to 120 with step of 10)\n",
    "n_neighbors_range = range(30, 121, 10)\n",
    "n_models = len(n_neighbors_range)\n",
    "\n",
    "print(f\"Creating {n_models} KNN models\")\n",
    "print(f\"n_neighbors values: {list(n_neighbors_range)}\")\n",
    "\n",
    "# Initialize storage for scores\n",
    "train_scores_list = []\n",
    "test_scores_list = []\n",
    "\n",
    "# Train each KNN model\n",
    "for i, n_neighbors in enumerate(n_neighbors_range):\n",
    "    print(f\"\\n--- Model {i+1}/{n_models}: KNN with n_neighbors={n_neighbors} ---\")\n",
    "    \n",
    "    # Create and fit the model\n",
    "    knn = KNN(n_neighbors=n_neighbors, contamination=contamination)\n",
    "    knn.fit(X_train_normalized)\n",
    "    \n",
    "    y_train_pred = knn.predict(X_train_normalized)\n",
    "    y_test_pred = knn.predict(X_test_normalized)\n",
    "    \n",
    "    train_ba = balanced_accuracy_score(y_train, y_train_pred)\n",
    "    test_ba = balanced_accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    print(f\"Train BA: {train_ba:.4f}\")\n",
    "    print(f\"Test BA: {test_ba:.4f}\")\n",
    "    \n",
    "    # Store the decision scores\n",
    "    train_scores = knn.decision_function(X_train_normalized)\n",
    "    test_scores = knn.decision_function(X_test_normalized)\n",
    "    \n",
    "    train_scores_list.append(train_scores)\n",
    "    test_scores_list.append(test_scores)\n",
    "\n",
    "print(\"All models trained successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef07199e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T08:50:36.176035Z",
     "start_time": "2025-10-28T08:50:36.171760Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train scores array shape: (10, 1281)\n",
      "Test scores array shape: (10, 550)\n"
     ]
    }
   ],
   "source": [
    "# Convert lists to numpy arrays for easier manipulation\n",
    "train_scores_array = np.array(train_scores_list)\n",
    "test_scores_array = np.array(test_scores_list)\n",
    "\n",
    "print(f\"Train scores array shape: {train_scores_array.shape}\")\n",
    "print(f\"Test scores array shape: {test_scores_array.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72ead3ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T08:50:40.627269Z",
     "start_time": "2025-10-28T08:50:40.609581Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores normalized using standardizer\n",
      "Normalized train scores shape: (1281, 10)\n",
      "Normalized test scores shape: (550, 10)\n"
     ]
    }
   ],
   "source": [
    "# Normalize the scores using standardizer\n",
    "# Standardize all train scores together (across all models (n_samples, n_models))\n",
    "train_scores_normalized = standardizer(train_scores_array.T)\n",
    "test_scores_normalized = standardizer(test_scores_array.T)\n",
    "\n",
    "print(\"Scores normalized using standardizer\")\n",
    "print(f\"Normalized train scores shape: {train_scores_normalized.shape}\")\n",
    "print(f\"Normalized test scores shape: {test_scores_normalized.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "070e979d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T08:50:44.356708Z",
     "start_time": "2025-10-28T08:50:44.347736Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average combination applied\n",
      "Average train scores shape: (1281,)\n",
      "Average test scores shape: (550,)\n"
     ]
    }
   ],
   "source": [
    "# Combine scores using average ( Not sure if it's all correct because i had to transpose )\n",
    "train_scores_avg = average(train_scores_normalized)\n",
    "test_scores_avg = average(test_scores_normalized)\n",
    "\n",
    "print(\"Average combination applied\")\n",
    "print(f\"Average train scores shape: {train_scores_avg.shape}\")\n",
    "print(f\"Average test scores shape: {test_scores_avg.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff5b5535",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T08:50:50.631915Z",
     "start_time": "2025-10-28T08:50:50.625489Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average threshold: 0.941179\n",
      "Average Strategy Results \n",
      "Train Balanced Accuracy: 0.7257\n",
      "Test Balanced Accuracy: 0.6925\n"
     ]
    }
   ],
   "source": [
    "# Find threshold using quantile with contamination\n",
    "threshold_avg = np.quantile(train_scores_avg, 1 - contamination)\n",
    "print(f\"Average threshold: {threshold_avg:.6f}\")\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred_avg = (train_scores_avg > threshold_avg).astype(int)\n",
    "y_test_pred_avg = (test_scores_avg > threshold_avg).astype(int)\n",
    "\n",
    "# Calculate balanced accuracy\n",
    "train_ba_avg = balanced_accuracy_score(y_train, y_train_pred_avg)\n",
    "test_ba_avg = balanced_accuracy_score(y_test, y_test_pred_avg)\n",
    "\n",
    "print(\"Average Strategy Results \")\n",
    "print(f\"Train Balanced Accuracy: {train_ba_avg:.4f}\")\n",
    "print(f\"Test Balanced Accuracy: {test_ba_avg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "571bceee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T08:51:18.514659Z",
     "start_time": "2025-10-28T08:51:18.509067Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximization combination applied\n",
      "Maximization train scores shape: (1281,)\n",
      "Maximization test scores shape: (550,)\n"
     ]
    }
   ],
   "source": [
    "# Combine scores using maximization strategy\n",
    "train_scores_max = maximization(train_scores_normalized)\n",
    "test_scores_max = maximization(test_scores_normalized)\n",
    "\n",
    "print(\"Maximization combination applied\")\n",
    "print(f\"Maximization train scores shape: {train_scores_max.shape}\")\n",
    "print(f\"Maximization test scores shape: {test_scores_max.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e14b96ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T08:51:40.685568Z",
     "start_time": "2025-10-28T08:51:40.672708Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximization strategy threshold: 1.041882\n",
      "Maximization Strategy Results\n",
      "Train Balanced Accuracy: 0.7482\n",
      "Test Balanced Accuracy: 0.7113\n"
     ]
    }
   ],
   "source": [
    "# Find threshold using quantile with contamination rate\n",
    "threshold_max = np.quantile(train_scores_max, 1 - contamination)\n",
    "print(f\"Maximization strategy threshold: {threshold_max:.6f}\")\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred_max = (train_scores_max > threshold_max).astype(int)\n",
    "y_test_pred_max = (test_scores_max > threshold_max).astype(int)\n",
    "\n",
    "# Calculate balanced accuracy\n",
    "train_ba_max = balanced_accuracy_score(y_train, y_train_pred_max)\n",
    "test_ba_max = balanced_accuracy_score(y_test, y_test_pred_max)\n",
    "\n",
    "print(f\"Maximization Strategy Results\")\n",
    "print(f\"Train Balanced Accuracy: {train_ba_max:.4f}\")\n",
    "print(f\"Test Balanced Accuracy: {test_ba_max:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f3a590b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T08:51:47.442082Z",
     "start_time": "2025-10-28T08:51:47.436994Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ENSEMBLE RESULTS SUMMARY\n",
      "============================================================\n",
      "\n",
      "Dataset: cardio.mat\n",
      "Contamination rate: 0.0960\n",
      "Number of models: 10\n",
      "n_neighbors range: [30, 40, 50, 60, 70, 80, 90, 100, 110, 120]\n",
      "\n",
      "Strategy             Train BA        Test BA        \n",
      "------------------------------------------------------------\n",
      "Average              0.7257          0.6925         \n",
      "Maximization         0.7482          0.7113         \n",
      "============================================================\n",
      "\n",
      "✓ Maximization strategy performs better on test set (+0.0189)\n"
     ]
    }
   ],
   "source": [
    "# Summary of results w ith formatted output\n",
    "print(\"=\"*60)\n",
    "print(\"ENSEMBLE RESULTS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nDataset: cardio.mat\")\n",
    "print(f\"Contamination rate: {contamination:.4f}\")\n",
    "print(f\"Number of models: {n_models}\")\n",
    "print(f\"n_neighbors range: {list(n_neighbors_range)}\")\n",
    "print(f\"\\n{'Strategy':<20} {'Train BA':<15} {'Test BA':<15}\")\n",
    "print(\"-\"*60)\n",
    "print(f\"{'Average':<20} {train_ba_avg:<15.4f} {test_ba_avg:<15.4f}\")\n",
    "print(f\"{'Maximization':<20} {train_ba_max:<15.4f} {test_ba_max:<15.4f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Determine which strategy performs better\n",
    "if test_ba_avg > test_ba_max:\n",
    "    print(f\"\\n✓ Average strategy performs better on test set (+{test_ba_avg - test_ba_max:.4f})\")\n",
    "elif test_ba_max > test_ba_avg:\n",
    "    print(f\"\\n✓ Maximization strategy performs better on test set (+{test_ba_max - test_ba_avg:.4f})\")\n",
    "else:\n",
    "    print(f\"\\n✓ Both strategies perform equally on test set\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
